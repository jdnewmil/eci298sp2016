---
title: "Floods Sample Analysis"
author: "Jeff Newmiller"
date: "May 8, 2016"
output: 
  html_document:
    fig_caption: yes
---

```{r, include=FALSE}
# To build this file
# If you are not already in the main project directory
# setwd('..')
# Once in the main project directory
# setwd( "Floods" )
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE )
source( "floods.R" )
library(ggplot2)
```

## Graphs

Trend lines for three reservoirs are given in Figure 1.

```{r, fig.cap="Figure 1. Annual Maximum Inflows and their Rolling 5-Year Mean"}
ggplot( floodsDFAlong, aes( x = WaterYear, y = value, color = variable ) ) +
  geom_line() +
  facet_wrap( ~Reservoir, ncol = 1 )
```

Figure 2 shows the density (smoothed histogram) for logarithm of annual maximum inflows to visually check for normality.

```{r, fig.cap="Figure 2. Distributions of $\\log{(\\mathit{MaxQ})}$"}
ggplot( logFloodsDFA, aes( x = logMaxInflow, color = Reservoir ) ) +
  geom_density() +
  xlim( c( 7, 13 ) )
```

Figure 3 shows a more statistical way to check for normality using quantile-quantile plots. We expect the points to fall on the line if the data conforms with the distribution.

```{r, fig.cap="Figure 3. Q-Q Plots for $\\log{(\\mathit{MaxQ})}$", fig.height=6}
# base graphics - see ?par
oldpar <- par( mfcol = c( 3, 1 ) )
# first part
qqnorm( log( floodListA[[ "FOL" ]]$maxInflow ), main = "a) Normal Q-Q Plot for FOL" )
qqline( log( floodListA[[ "FOL" ]]$maxInflow ) )
# second part
qqnorm( log( floodListA[[ "ORO" ]]$maxInflow ), main = "b) Normal Q-Q Plot for ORO" )
qqline( log( floodListA[[ "ORO" ]]$maxInflow ) )
# third part
qqnorm( log( floodListA[[ "SHA" ]]$maxInflow ), main = "c) Normal Q-Q Plot for SHA" )
qqline( log( floodListA[[ "SHA" ]]$maxInflow ) )
par( oldpar )
```

Table 1 shows the extrapolation of 100-year flood level events. The 2006 flood in Folsom stands out from the rest of the flows so much that it exceeds the 100-year expectation derived from the overall data set.

```{r,results='asis'}
knitr::kable( floodsLongTerm
            , caption = "Table 1. Long Term Flood Results"
            , digits = c( 0, 0, 0 )
            )
```

# Data Flow

Figure 4 shows the significant processing steps in this analysis.

```{r,fig.width=7.5,fig.height=9}
library(DiagrammeR)
grViz('
digraph Floods {
  node [ shape = none ]
  origdtadir [ label = "\\"../data/floods/original/\\"" ]
  cleandtadir [label =  "\\"../data/floods/clean/\\"" ]
  rmdfile [ label = "\\"floods.Rmd\\"" ]
  htmlfile [ label = "\\"floods.html\\"" ]
  node [ shape = box ]
  reservoirs
  start
  stop
  ffillcols

  subgraph cluster_input{
    label = "Input"
    style = dashed
    node [ shape = ellipse ]
    readReservoirDaily [ label = "readReservoirDaily()" ]
  }
  subgraph cluster_analysis{
    label = "Analysis"
    style = dashed
    node [ shape = box ]
    floodList
    floodListA
    floodsDFA
    floodsDFAlong
    logFloodsDFA
    floodsLongTerm
    node [ shape = ellipse ]
    cleanReservoirDaily [ label = "cleanReservoirDaily()" ]
    crunchA
    bindrows [ label = "bind_rows()" ]
    gatherDFA [ label = "gather()" ]
    mutateLog [ label = "mutate(log())" ]
    groupbyReservoir [ label = "group_by(Reservoir)" ]
  }
  subgraph cluster_output{
    label = "Output"
    style = dashed
    node [ shape = ellipse ]
    writecsv [ label = "write.csv()" ]
    makeReservoirFname [ label = "makeReservoirFname()" ]
    knitrmd
  }

  reservoirs -> readReservoirDaily
  origdtadir -> readReservoirDaily
  readReservoirDaily -> cleanReservoirDaily
  start -> cleanReservoirDaily
  stop -> cleanReservoirDaily
  ffillcols -> cleanReservoirDaily
  
  cleanReservoirDaily -> floodList
  floodList -> crunchA
  crunchA -> floodListA
  floodListA -> bindrows
  bindrows -> floodsDFA
  floodsDFA -> gatherDFA
  floodsDFA -> knitrmd
  gatherDFA -> floodsDFAlong
  floodsDFAlong -> knitrmd
  floodsDFA -> mutateLog
  mutateLog -> logFloodsDFA
  logFloodsDFA -> knitrmd
  floodsDFA -> groupbyReservoir
  groupbyReservoir -> floodsLongTerm
  floodsLongTerm -> knitrmd

  reservoirs -> makeReservoirFname
  makeReservoirFname -> writecsv
  floodList -> writecsv
  writecsv -> cleandtadir

  rmdfile -> knitrmd
  knitrmd -> htmlfile
}
')
```
Figure 4. Data flow for `floods` analysis
